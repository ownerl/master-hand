# Project Pitch

Create a web-app that utilizes MediaPipe's pose tracking system to control and navigate using hand gestures and motions. The primary goal will be to properly receive and execute functions based on gestures. This will require creating a data set and training a model to recognize these gestures and/or manually creating point based gesture groups and matching them to the hand's points.

## Tech Stack

- JS
- Python
- MediaPipe
- OpenCV

## Sprints/Daily Goals

- Learn to create dataset
- Train AI to recognize gestures from the dataset
- Allow AI to execute functions based on recognized gestures
- Create rudimentary web-app to feature the hand tracking system
- ???
- Profit

## Wireframes

![literally wireframe](<public/Screenshot 2023-12-13 at 1.00.13 PM.png>)